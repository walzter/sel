{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest & Decision Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dictionary for the dataset name & paths \n",
    "DATASETS ={\n",
    "    \"small\":\"../Data/small/glass.data\",\n",
    "    \"medium\":\"../Data/medium/drug_consumption.data\",\n",
    "    \"large\":\"../Data/large/c2k_data_comma.csv\"\n",
    "               }\n",
    "\n",
    "## Data Split Parameters \n",
    "TRAIN_SIZE = 0.8\n",
    "TEST_SIZE = 1 - TRAIN_SIZE\n",
    "\n",
    "## Random Forest Parameters\n",
    "NUM_TREES = 100 ## 1,10,25,50,75,100 \n",
    "NUM_FEATURES = 10  ## 1,3, int(log_2(M)+1), sqrt(M), where M is the number of features\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    \"\"\"\n",
    "    Loads the dataset from the dictionary.\n",
    "    \"\"\"\n",
    "    if dataset_name == 'small':\n",
    "        ## exclude the first column ID (labeled 0 to 10, so use 1-10)\n",
    "        df = pd.read_csv(DATASETS[dataset_name],header=None)\n",
    "        df.drop(df.columns[0], axis=1, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data: pd.DataFrame, train_size: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets.\n",
    "    \"\"\"\n",
    "    train_data = data.sample(frac=train_size, random_state=RANDOM_STATE)\n",
    "    test_data = data.drop(train_data.index)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data \n",
    "small = load_dataset(\"small\")\n",
    "\n",
    "## split the data \n",
    "train, test = split_train_test(small, TRAIN_SIZE)\n",
    "## split the train into features and labels\n",
    "X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split a numpy array into two parts \n",
    "## the first part is the left branch, the second part is the right branch\n",
    "def split_data(data: np.array, index: int, value: float) -> (np.array, np.array):\n",
    "    \"\"\"\n",
    "    Splits the dataset based on the column and value.\n",
    "    \"\"\"\n",
    "    left = data[data[:, index] <= value]\n",
    "    right = data[data[:, index] > value]\n",
    "    return left, right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the entropy function \n",
    "def entropy(data:np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the entropy given the following formula: \n",
    "    H(x) = -sum_j(p_j * log(p_j))\n",
    "    \"\"\"\n",
    "    ## get the unique counts of the array \n",
    "    _, counts = np.unique(data, return_counts=True)\n",
    "    ## get the probabilities\n",
    "    probas = counts / data.shape[0]\n",
    "    ## add the 1e-7 to avoid log(0)\n",
    "    #return np.sum(-probas * np.log2(probas + 1e-7))\n",
    "    return -(probas * np.log(probas) + (1 - probas) * np.log(1 - probas)).sum()\n",
    "\n",
    "## define the gini function \n",
    "def gini(data: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the gini impurity given the following formula:\n",
    "    G(x) = 1 - sum_j(p_j^2)\n",
    "    \"\"\"\n",
    "    ## get the unique counts of the array \n",
    "    _, counts = np.unique(data, return_counts=True)\n",
    "    ## get the probabilities\n",
    "    probas = counts / data.shape[0]\n",
    "    return 1 - np.sum(probas ** 2)\n",
    "\n",
    "## define the same function but given a probability \n",
    "## wheere the input is p(x)\n",
    "\n",
    "def entropy_proba(proba: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the entropy given the following formula:\n",
    "    H(x) = -sum_j(p_j * log(p_j))\n",
    "    \"\"\"\n",
    "    if proba == 0: \n",
    "        return 0\n",
    "    elif proba == 1:\n",
    "        return 0 \n",
    "    else: \n",
    "        return -proba * np.log2(proba) - (1 - proba) * np.log2(1 - proba)\n",
    "    \n",
    "## define the information gain function \n",
    "def information_gain(left_branch, right_branch) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the information gain given the following formula:\n",
    "    G(x) = H(x) - sum_j(p_j * H(x|j))\n",
    "    \"\"\"\n",
    "    p = len(left_branch) / (len(left_branch) + len(right_branch))\n",
    "    return entropy(left_branch) + entropy(right_branch) - p * entropy(left_branch) - (1 - p) * entropy(right_branch)\n",
    "\n",
    "## define a function to draw bootstrap samples \n",
    "## from X_train & y_train\n",
    "def get_bootstrap_samples(X_train:np.array, y_train:np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Function which gets the bootstrap samples.\n",
    "    These are samples WITH replacement, thus, the left over samples are \n",
    "    Left_Over = lim_x_to_inf [(1 - 1/n)^n] -> e^-1 ~ 1/3\n",
    "    So for the fitting 2/3 of the observations will be used. \n",
    "    \n",
    "    PARAMS:\n",
    "    -------\n",
    "    X_train : training samples of the dataset \n",
    "    \n",
    "    y_train : training labels of the dataset \n",
    "    \n",
    "    RETURNS:\n",
    "    --------\n",
    "    X_bootstrap : bootstrap samples for X_train \n",
    "    \n",
    "    y_bootstrap : bootstrap samples for y_train \n",
    "    \n",
    "    x_oob : out of bag samples for X_train \n",
    "    \n",
    "    y_oob : out of bag samples for y_train \n",
    "    \n",
    "    \"\"\"\n",
    "    ## first get the indices of the bootstrap samples \n",
    "    bootstrap_idx = np.random.choice(range(X_train.shape[0]), size=int(X_train.shape[0]), replace=True)\n",
    "    ## get the out of bag samples\n",
    "    oob_idx = np.setdiff1d(range(X_train.shape[0]), bootstrap_idx)\n",
    "    ## get the bootstrap samples\n",
    "    x_bootstrap, y_bootstrap = X_train.iloc[bootstrap_idx].values, y_train.iloc[bootstrap_idx].values\n",
    "    ## get the oob samples \n",
    "    x_oob,y_oob = X_train[oob_idx].values, y_train[oob_idx].values\n",
    "    return x_bootstrap, y_bootstrap, x_oob, y_oob\n",
    "\n",
    "## define a function to calculate the OOB error\n",
    "def out_of_bag_error(x_test:np.array, y_test:np.array, model:object) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the out of bag error given the following formula:\n",
    "    E_OOB = 1/n * sum_i(1 - p(x_i|y_i))\n",
    "    \"\"\"\n",
    "    ## get the predictions for each item in the test set\n",
    "    preds = np.array([predict_samples(model, i) for i in x_test])\n",
    "    ## get the sum of the mismatches \n",
    "    mismatch = np.sum(preds != y_test)\n",
    "    ## return the error\n",
    "    return mismatch / y_test.shape[0]\n",
    "\n",
    "## define a function to find the best split point \n",
    "## it should select m features at random \n",
    "## for each feature in the bootstrapped samples, it calculates the information gain\n",
    "## returns a dictionary with: feature index, split value, left_branch, right_branch\n",
    "\n",
    "def best_split_finder(X_bootstrap: np.array, y_bootstrap: np.array, num_features: int) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates the best split for each feature in the bootstrapped samples.\n",
    "    \n",
    "    PARAMS: \n",
    "    X_bootstrap : training bootstrapped samples \n",
    "    \n",
    "    y_bootstrap : training labels boostrapped samples\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0, 10, 11, 13, 16, 17, 19, 20, 21, 22, 25, 28, 29, 31, 35, 36, 37, 40, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 57, 59, 60, 62, 63, 64, 66, 67, 70, 71, 73, 75, 76, 78, 79, 82, 83, 84, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 124, 125, 126, 127, 131, 132, 136, 138, 141, 144, 146, 149, 151, 152, 153, 154, 155, 156, 162, 164, 165, 166, 167, 168, 169] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bd/f5z4cc193xgdxq1yr1xpflmm0000gn/T/ipykernel_7361/527207407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_bootstrap_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/bd/f5z4cc193xgdxq1yr1xpflmm0000gn/T/ipykernel_7361/3910088247.py\u001b[0m in \u001b[0;36mget_bootstrap_samples\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0moob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m## get the bootstrap samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mx_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbootstrap_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbootstrap_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;31m## get the oob samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mx_oob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_oob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moob_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ci_covid/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ci_covid/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ci_covid/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0, 10, 11, 13, 16, 17, 19, 20, 21, 22, 25, 28, 29, 31, 35, 36, 37, 40, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 57, 59, 60, 62, 63, 64, 66, 67, 70, 71, 73, 75, 76, 78, 79, 82, 83, 84, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 124, 125, 126, 127, 131, 132, 136, 138, 141, 144, 146, 149, 151, 152, 153, 154, 155, 156, 162, 164, 165, 166, 167, 168, 169] not in index'"
     ]
    }
   ],
   "source": [
    "get_bootstrap_samples(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6858c3dbc49267e902ff986705b591b9d7b57befff84fd7d814fe16c4a8e1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
