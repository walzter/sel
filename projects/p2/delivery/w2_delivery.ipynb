{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR4jUXP5jqj3"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U__QKQs7jnX6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FwHQ_zl1e1fT"
      },
      "outputs": [],
      "source": [
        "logging.getLogger().setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgxfwrOwjsKo"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm3g2VrZcrjb"
      },
      "source": [
        "## Cart learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HD0MoBQ9jtXm"
      },
      "outputs": [],
      "source": [
        "class Cart:\n",
        "  def __init__(self, x_train, y_train, n_features, n_depth, recalculate_features=True):\n",
        "    self.x_train = x_train\n",
        "    self.y_train = y_train\n",
        "    self.labels = np.unique(y_train)\n",
        "    self.n_features = n_features\n",
        "    self.n_depth = n_depth\n",
        "    self.recalculate_features = recalculate_features\n",
        "    self.root = None\n",
        "    self.features = np.array([])\n",
        "    self.features = self._get_features()\n",
        "    return\n",
        "\n",
        "  def train(self):\n",
        "    instances = np.arange(self.x_train.shape[0])\n",
        "    root = self._find_node(instances)\n",
        "    root = self._expand_tree(root, 1)\n",
        "    self.root = root\n",
        "    if root is None:\n",
        "      logging.error('Root None: %s', root)\n",
        "    return root\n",
        "\n",
        "  def predict(self, x_pred):\n",
        "    return self._predict(self.root, x_pred)\n",
        "\n",
        "  def _predict(self, node, x_pred):\n",
        "    if node is None:\n",
        "      logging.error('Predicting node is none: %s', node)\n",
        "\n",
        "    if x_pred[node['feature']] < node['middle_point']:\n",
        "      if isinstance(node['l'], dict):\n",
        "        return self._predict(node['l'], x_pred)\n",
        "\n",
        "      return node['l']\n",
        "\n",
        "    if isinstance(node['r'], dict):\n",
        "      return self._predict(node['r'], x_pred)\n",
        "\n",
        "    return node['r']\n",
        "\n",
        "  def _build_leaf(self, branch):\n",
        "    lbls, clbls = np.unique(self.y_train[branch], return_counts=True)\n",
        "    max_lbl = lbls[np.argmax(clbls)]\n",
        "\n",
        "    return max_lbl\n",
        "\n",
        "  def _expand_tree(self, node, depth):\n",
        "    l, r = node['branch']\n",
        "    node['depth'] = depth\n",
        "    del(node['branch'])\n",
        "\n",
        "    if l.size == 0 or r.size == 0:\n",
        "      node['l'] = node['r'] = self._build_leaf(np.concatenate((l, r)))\n",
        "      return node\n",
        "\n",
        "    if depth >= self.n_depth:\n",
        "      logging.debug('Max depth reached')\n",
        "      node['l'] = self._build_leaf(l)\n",
        "      node['r'] = self._build_leaf(r)\n",
        "      return node\n",
        "\n",
        "    node['l'] = self._find_node(l)\n",
        "    self._expand_tree(node['l'], depth+1)\n",
        "    node['r'] = self._find_node(r)\n",
        "    self._expand_tree(node['r'], depth+1)\n",
        "\n",
        "    return node\n",
        "\n",
        "  def _get_features(self):\n",
        "    if self.recalculate_features == True or self.features.size == 0:\n",
        "      return np.random.permutation(self.x_train.shape[1])[:self.n_features]\n",
        "\n",
        "    return self.features\n",
        "\n",
        "  def _clear_feature(self, idx):\n",
        "    if self.recalculate_features == True:\n",
        "      return\n",
        "\n",
        "    curr_features = self.features\n",
        "    self.features = curr_features[curr_features != idx]\n",
        "\n",
        "  def _find_node(self, instances):\n",
        "    #eval_features = np.random.choice(self.x_train.shape[1], self.n_features)\n",
        "    eval_features = self._get_features()\n",
        "    best_feature, best_gini, best_branch, best_value = -1, 1, None, None\n",
        "\n",
        "    logging.debug('Features to consider for node: %s', eval_features)\n",
        "    for feature in eval_features:\n",
        "      branches, value = self._binary_split(feature, instances)\n",
        "      logging.debug('Evaluating idx: %s', feature)\n",
        "      curr_gini = self._gini_index(branches)\n",
        "      logging.debug('Current gini value: %s', curr_gini)\n",
        "\n",
        "      if curr_gini < best_gini or best_value == None:\n",
        "        best_gini = curr_gini\n",
        "        best_branch = branches\n",
        "        best_feature = feature\n",
        "        best_value = value\n",
        "\n",
        "    logging.debug('Best node as: best_feature %s, best_value: %s, best_gini: %s, best_branch: %s', best_feature, best_value, best_gini, best_branch)\n",
        "    self._clear_feature(best_feature)\n",
        "    return {'gini': best_gini, 'branch': best_branch, 'feature': best_feature, 'middle_point': best_value}\n",
        "\n",
        "  def _binary_split(self, feature, instances):\n",
        "    # assumes continuous data\n",
        "    sorted_data = np.sort(self.x_train[instances, feature])\n",
        "    middle_point = sorted_data[(int(sorted_data.shape[0]/2))]\n",
        "\n",
        "    l = np.where(self.x_train[instances, feature] < middle_point)[0]\n",
        "    r = np.where(self.x_train[instances, feature] >= middle_point)[0]\n",
        "\n",
        "    return [l, r], middle_point\n",
        "\n",
        "  def _gini_index(self, branches):\n",
        "    n_instances = len(branches[0]) + len(branches[1])\n",
        "    gini_score = 0.0\n",
        "\n",
        "    logging.debug('Evaluating gini on branch: %s', branches)\n",
        "    for branch in branches:\n",
        "      if branch.shape == 0:\n",
        "        continue\n",
        "\n",
        "      _, all_p = np.unique(self.y_train[branch], return_counts=True)\n",
        "      branch_score = np.sum(np.power(all_p/branch.shape, 2))\n",
        "      gini_score += (1.0 - branch_score) * (branch.shape[0] / n_instances)\n",
        "      logging.debug('Accumulated gini: %s', gini_score)\n",
        "    return gini_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Am6F6CLxZy4"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jla5jl8Cxby0"
      },
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "  def __init__(self, learner, n_trees, n_features, n_depth, x_train, y_train, sampling=True, recalculate_features=True):\n",
        "    self.learner = learner\n",
        "    self.n_trees = n_trees\n",
        "    self.n_features = n_features\n",
        "    self.n_depth = n_depth\n",
        "    self.x_train = x_train\n",
        "    self.y_train = y_train\n",
        "    self.trees = []\n",
        "    self._init_learners()\n",
        "\n",
        "  def _init_learners(self, sampling=True, recalculate_features=True):\n",
        "    trees = []\n",
        "\n",
        "    for curr in range(self.n_trees):\n",
        "      x_train_sample, y_train_sample = self._get_sampling(sampling)\n",
        "      trees.append(self.learner(x_train_sample, y_train_sample, self.n_features, self.n_depth, recalculate_features=True))\n",
        "\n",
        "    self.trees = trees\n",
        "    return\n",
        "\n",
        "  def _get_sampling(self, sampling=True):\n",
        "    if sampling == False:\n",
        "      return self.x_train, self.y_train\n",
        "\n",
        "    sample_idxs = np.random.choice(self.x_train.shape[0], int(self.x_train.shape[0] * 0.8))\n",
        "    return self.x_train[sample_idxs], self.y_train[sample_idxs]\n",
        "\n",
        "  def train(self):\n",
        "    for curr_tree in self.trees:\n",
        "      curr_tree.train()\n",
        "\n",
        "  def predict(self, x_pred):\n",
        "    y_pred = []\n",
        "    for curr_tree in self.trees:\n",
        "      y_pred.append(curr_tree.predict(x_pred))\n",
        "  \n",
        "    votes = np.unique(y_pred, return_counts=True)\n",
        "    popular = np.argmax(votes[1])\n",
        "\n",
        "    return votes[0][popular], votes[1][popular]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDXH-NpPxeFS"
      },
      "source": [
        "## Decision forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CikxNTFmxfaw"
      },
      "outputs": [],
      "source": [
        "class DecisionForest(RandomForest):\n",
        "  def __init__(self, learner, n_trees, n_features, n_depth, x_train, y_train, sampling=False, recalculate_features=False):\n",
        "    super().__init__(learner, n_trees, n_features, n_depth, x_train, y_train, sampling, recalculate_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJzLh67Gi4x1"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USyft-puMJUz"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n7HoPyNIMKgg"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "  return np.count_nonzero(y_true == y_pred) / y_true.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rRMrkvVcWXjJ"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = \"./Data\"\n",
        "SIZE='small'\n",
        "FN = \"glass.data\"\n",
        "\n",
        "def load_ds(file_name):\n",
        "  #file_name = root_path + file_name\n",
        "  df = pd.read_csv(BASE_PATH + f'/{SIZE}/' + file_name,header=None)\n",
        "  inputs = df.iloc[:,:-1]\n",
        "  outputs = df.iloc[:,-1]\n",
        "  #inputs  = df.drop(columns=[\"class\"])\n",
        "  #outputs = df[\"class\"]\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(inputs,outputs,test_size=0.1, random_state=42)\n",
        "\n",
        "  return df, X_train.reset_index(drop=True), X_test.reset_index(drop=True), Y_train.reset_index(drop=True), Y_test.reset_index(drop=True)\n",
        "\n",
        "df, X_train, X_test, Y_train, Y_test = load_ds(FN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L10p_yYbZw7D"
      },
      "outputs": [],
      "source": [
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
        "                            np.int16, np.int32, np.int64, np.uint8,\n",
        "                            np.uint16, np.uint32, np.uint64)):\n",
        "\n",
        "            return int(obj)\n",
        "\n",
        "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
        "            return float(obj)\n",
        "\n",
        "        elif isinstance(obj, (np.complex_, np.complex64, np.complex128)):\n",
        "            return {'real': obj.real, 'imag': obj.imag}\n",
        "\n",
        "        elif isinstance(obj, (np.ndarray,)):\n",
        "            return obj.tolist()\n",
        "\n",
        "        elif isinstance(obj, (np.bool_)):\n",
        "            return bool(obj)\n",
        "\n",
        "        elif isinstance(obj, (np.void)): \n",
        "            return None\n",
        "\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "def write_results(results, dsname, algorithm):\n",
        "  with open(BASE_PATH + '/out/' + dsname + '_' + algorithm + '.json', 'w') as fp:\n",
        "    json.dump(results, fp, cls=NumpyEncoder)\n",
        "  return\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dBCc8nycvjm"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rtrHNNtZLy-0"
      },
      "outputs": [],
      "source": [
        "def random_forest_evaluation(x_train, y_train, x_pred, y_true):\n",
        "  features_size = x_train.shape[1]\n",
        "  n_trees = [1, 10, 25, 50, 75, 100]\n",
        "  n_features = [1, 3, int(np.log2(features_size) + 1), int(np.sqrt(features_size))]\n",
        "  tree_depth = 10\n",
        "  results = []\n",
        "\n",
        "  for t_conf in n_trees:\n",
        "    for f_conf in n_features:\n",
        "      logging.info('Building n_trees: %s, n_features: %s, depth: %s', t_conf, f_conf, tree_depth)\n",
        "      model = RandomForest(Cart, t_conf, f_conf, tree_depth, x_train, y_train)\n",
        "      model.train()\n",
        "      y_pred = []\n",
        "\n",
        "      for x_pred_i in x_pred:\n",
        "        y_pred.append(model.predict(x_pred_i)[0])\n",
        "\n",
        "      acc = evaluate_model(y_true, y_pred)\n",
        "      results.append({\n",
        "          'n_tree': t_conf,\n",
        "          'n_features': f_conf,\n",
        "          'tree_depth': tree_depth,\n",
        "          'accuracy': acc\n",
        "      })\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I8r_H3L4YNtB"
      },
      "outputs": [],
      "source": [
        "def decision_forest_evaluation(x_train, y_train, x_pred, y_true):\n",
        "  features_size = x_train.shape[1]\n",
        "  n_trees = [1, 10, 25, 50, 75, 100]\n",
        "  n_features = [int(features_size/4)+1, int(features_size/2), int(3*features_size/4), ]\n",
        "  tree_depth = 10\n",
        "  results = []\n",
        "\n",
        "  for t_conf in n_trees:\n",
        "    for f_conf in n_features:\n",
        "      logging.info('Building n_trees: %s, n_features: %s, depth: %s', t_conf, f_conf, tree_depth)\n",
        "      model = DecisionForest(Cart, t_conf, f_conf, tree_depth, x_train, y_train, sampling=False, recalculate_features=False)\n",
        "      model.train()\n",
        "      y_pred = []\n",
        "\n",
        "      for x_pred_i in x_pred:\n",
        "        y_pred.append(model.predict(x_pred_i)[0])\n",
        "\n",
        "      acc = evaluate_model(y_true, y_pred)\n",
        "      results.append({\n",
        "          'n_tree': t_conf,\n",
        "          'n_features': f_conf,\n",
        "          'tree_depth': tree_depth,\n",
        "          'accuracy': acc,\n",
        "          'y_pred': y_pred,\n",
        "          'y_true': y_true\n",
        "      })\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eo0nli5Vcea5"
      },
      "outputs": [],
      "source": [
        "def run_small():\n",
        "  file_name = 'glass.data'\n",
        "  df, X_train, X_test, Y_train, Y_test = load_ds(file_name)\n",
        "  results_random = random_forest_evaluation(X_train.to_numpy(), Y_train.to_numpy(), X_test.to_numpy(), Y_test.to_numpy())\n",
        "  results_decision = decision_forest_evaluation(X_train.to_numpy(), Y_train.to_numpy(), X_test.to_numpy(), Y_test.to_numpy())\n",
        "  write_results(results_random, 'glass', 'random')\n",
        "  write_results(results_decision, 'glass', 'decision')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAALK1Oqe-oo"
      },
      "outputs": [],
      "source": [
        "def run_data_banknote_authentication():\n",
        "  file_name = 'data_banknote_authentication.csv'\n",
        "  df, X_train, X_test, Y_train, Y_test = load_ds(file_name)\n",
        "  results_random = random_forest_evaluation(X_train.to_numpy(), Y_train.to_numpy(), X_test.to_numpy(), Y_test.to_numpy())\n",
        "  results_decision = decision_forest_evaluation(X_train.to_numpy(), Y_train.to_numpy(), X_test.to_numpy(), Y_test.to_numpy())\n",
        "  write_results(results_random, 'data_banknote_authentication', 'random')\n",
        "  write_results(results_decision, 'data_banknote_authentication', 'decision')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXBHVUGerodH",
        "outputId": "fd3f599e-1788-418f-a385-ae77481cddb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Building n_trees: 1, n_features: 1, depth: 10\n",
            "INFO:root:Building n_trees: 1, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 1, n_features: 4, depth: 10\n",
            "INFO:root:Building n_trees: 1, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 10, n_features: 1, depth: 10\n",
            "INFO:root:Building n_trees: 10, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 10, n_features: 4, depth: 10\n",
            "INFO:root:Building n_trees: 10, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 25, n_features: 1, depth: 10\n",
            "INFO:root:Building n_trees: 25, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 25, n_features: 4, depth: 10\n",
            "INFO:root:Building n_trees: 25, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 50, n_features: 1, depth: 10\n",
            "INFO:root:Building n_trees: 50, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 50, n_features: 4, depth: 10\n",
            "INFO:root:Building n_trees: 50, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 75, n_features: 1, depth: 10\n",
            "INFO:root:Building n_trees: 75, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 75, n_features: 4, depth: 10\n",
            "INFO:root:Building n_trees: 75, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 100, n_features: 1, depth: 10\n",
            "INFO:root:Building n_trees: 100, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 100, n_features: 4, depth: 10\n",
            "INFO:root:Building n_trees: 100, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 1, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 1, n_features: 5, depth: 10\n",
            "INFO:root:Building n_trees: 1, n_features: 7, depth: 10\n",
            "INFO:root:Building n_trees: 10, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 10, n_features: 5, depth: 10\n",
            "INFO:root:Building n_trees: 10, n_features: 7, depth: 10\n",
            "INFO:root:Building n_trees: 25, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 25, n_features: 5, depth: 10\n",
            "INFO:root:Building n_trees: 25, n_features: 7, depth: 10\n",
            "INFO:root:Building n_trees: 50, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 50, n_features: 5, depth: 10\n",
            "INFO:root:Building n_trees: 50, n_features: 7, depth: 10\n",
            "INFO:root:Building n_trees: 75, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 75, n_features: 5, depth: 10\n",
            "INFO:root:Building n_trees: 75, n_features: 7, depth: 10\n",
            "INFO:root:Building n_trees: 100, n_features: 3, depth: 10\n",
            "INFO:root:Building n_trees: 100, n_features: 5, depth: 10\n",
            "INFO:root:Building n_trees: 100, n_features: 7, depth: 10\n"
          ]
        }
      ],
      "source": [
        "run_small()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BDXH-NpPxeFS"
      ],
      "name": "w2-delivery",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "ac6858c3dbc49267e902ff986705b591b9d7b57befff84fd7d814fe16c4a8e1f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
