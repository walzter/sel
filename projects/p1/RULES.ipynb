{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpers \n",
    "from helpers.config import make_config\n",
    "from helpers.Cleaner.Cleaner import Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: Small  \n",
      "For n_features, the value is: 10\n",
      "For column_names, the value is: ['Class', 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat']\n"
     ]
    }
   ],
   "source": [
    "## data size\n",
    "data_size = 'small' # 'medium', # 'large'\n",
    "## define directories\n",
    "#DATA_DIR, OUT_DIR = \"raw_data\",\"out\"\n",
    "## make the config file \n",
    "CONFIG = make_config()\n",
    "\n",
    "## cleaning\n",
    "df = Cleaner(CONFIG[data_size], data_size, CONFIG[\"OUT_DIR\"], CONFIG['VERBOSITY'])._make_dataframe()\n",
    "# ## processing \n",
    "# proc = Processor(dataframe = df, config = CONFIG, size = data_size)\n",
    "# ## get the mapping \n",
    "# small_mapper = proc._process()\n",
    "# ## mapping forwards \n",
    "# dff = proc._forwards_backwards_map(df, small_mapper,direction='f') ## works with forwards, forw, f\n",
    "## mapping backwards \n",
    "### dfb =  proc._forwards_backwards_map(small_df, proc.holder,direction='b') ## works with backwards, back, b \n",
    "df.columns = list(range(0,len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING-TESTING SPLIT = 10.0%/90.0%\n",
      "TRAINING - Number of Samples = 27\n",
      "TESTING  - Number of Samples = 250\n"
     ]
    }
   ],
   "source": [
    "from helpers.RULES.RULES import RULES\n",
    "rules = RULES(train_split = CONFIG[\"TRAIN_SPLIT\"], \n",
    "              dataframe = df,\n",
    "              class_idx=CONFIG[\"CLASS_INDEX\"],\n",
    "              verbose=True,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[47m\u001b[31mIF 3 = 25-29  THEN no-recurrence-events | Coverage: 6 - Number of instances covered: 22.22%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 1 = 50-59  THEN no-recurrence-events | Coverage: 5 - Number of instances covered: 18.52%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 3 = 15-19  THEN no-recurrence-events | Coverage: 1 - Number of instances covered: 3.70%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 2 = ge40 AND 3 = 30-34  THEN no-recurrence-events | Coverage: 1 - Number of instances covered: 3.70%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 2 = premeno AND 3 = 20-24  THEN no-recurrence-events | Coverage: 1 - Number of instances covered: 3.70%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 5 = yes  THEN recurrence-events | Coverage: 3 - Number of instances covered: 11.11%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 4 = 3-5  THEN recurrence-events | Coverage: 2 - Number of instances covered: 7.41%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 1 = 60-69  THEN no-recurrence-events | Coverage: 2 - Number of instances covered: 7.41%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 1 = 40-49  THEN no-recurrence-events | Coverage: 4 - Number of instances covered: 14.81%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 3 = 30-34  THEN no-recurrence-events | Coverage: 1 - Number of instances covered: 3.70%\u001b[0m\n",
      "\u001b[47m\u001b[31mIF 1 = 30-39  THEN recurrence-events | Coverage: 1 - Number of instances covered: 3.70%\u001b[0m\n",
      "Number of rules derived from the training-set: 11\n"
     ]
    }
   ],
   "source": [
    "## run RULES\n",
    "dat = rules._run_RULES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mIF 3 = 25-29  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 72 | Pct-Coverage: 28.80 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 1 = 50-59  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 114 | Pct-Coverage: 45.60 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 3 = 15-19  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 31 | Pct-Coverage: 12.40 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 2 = ge40 AND 3 = 30-34  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 21 | Pct-Coverage: 8.40 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 2 = premeno AND 3 = 20-24  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 39 | Pct-Coverage: 15.60 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 5 = yes  THEN recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 23 | Pct-Coverage: 9.20 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 4 = 3-5  THEN recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 6 | Pct-Coverage: 2.40 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 1 = 60-69  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 31 | Pct-Coverage: 12.40 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 1 = 40-49  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 54 | Pct-Coverage: 21.60 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 3 = 30-34  THEN no-recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 5 | Pct-Coverage: 2.00 | Precision 100.0\u001b[0m\n",
      "\u001b[32mIF 1 = 30-39  THEN recurrence-events\u001b[0m \u001b[47m\u001b[31mCoverage: 12 | Pct-Coverage: 4.80 | Precision 100.0\u001b[0m\n",
      "\u001b[31mFINAL ACCURACY: 65.60%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rules._predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build a function to normalize a column of a dataframe \n",
    "\n",
    "def normalize_column(df, col_name):\n",
    "    \"\"\"\n",
    "    Normalize a column of a dataframe\n",
    "    \"\"\"\n",
    "    col = df[col_name]\n",
    "    col_min = col.min()\n",
    "    col_max = col.max()\n",
    "    col_norm = (col - col_min) / (col_max - col_min)\n",
    "    return col_norm"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3631b590a110192d13b5e100232a74a3493f1a552dda16ee8d5c788835523d9e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('p1-SzUQeW0v')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
